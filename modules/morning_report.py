from __future__ import annotations
from dataclasses import dataclass
from datetime import date
import json, os
import streamlit as st, pandas as pd
from typing import List, Any
from .styling import pill, color_block

@dataclass
class MorningReport:
    provider: Any
    regions: List[str]
    session_date: date

    # ---------- Section 1: Macro Header ----------
    def render_macro_header(self):
        m = self.provider.get_macro_snapshot()
        st.markdown(f"### North America Morning Report ‚Äî {self.session_date.strftime('%a %b %d, %Y')}")
        st.write(
            f"**Tone:** {m['tone']}  "
            f"{pill('USD ' + m['usd'], m['usd'])} "
            f"{pill('Gold ' + m['gold'], m['gold'])} "
            f"{pill('Oil ' + m['oil'], m['oil'])} "
            f"{pill('Rates ' + m['rates'], m['rates'])} "
            f"{pill('VIX ' + m['vix'], m['vix'])}",
            unsafe_allow_html=True
        )
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("SPY", m['indices']['SPY']['level'], m['indices']['SPY']['pct'])
        c2.metric("QQQ", m['indices']['QQQ']['level'], m['indices']['QQQ']['pct'])
        c3.metric("IWM", m['indices']['IWM']['level'], m['indices']['IWM']['pct'])
        c4.metric("VIX", m['vix_level'], m['vix_chg'])

    # ---------- Section 2: Benchmark & Breadth Matrix ----------
    def render_benchmark_and_breadth_matrix(self):
        d = self.provider.get_benchmark_and_breadth()
        st.markdown("## üìä Benchmark & Breadth Matrix")
        st.dataframe(pd.DataFrame(d['benchmarks']).set_index("Index"), use_container_width=True)
        st.markdown("### Sector Breadth Matrix")
        st.dataframe(pd.DataFrame(d['sectors']).set_index("Sector"), use_container_width=True)
        st.info("Takeaway: " + d['takeaway'])

    # ---------- Section 3: Options & Skews ----------
    def render_options_and_skews(self):
        st.markdown("## üßÆ Options Flow & Skews")
        for r in self.provider.get_options_skews():
            st.write(f"**{r['ticker']}** ‚Äî IVR {r['ivr']}; skew: {r['skew']} ‚Üí **Plan:** {r['plan']}")

    # ---------- Section 4: Catalyst Board ----------
    def render_catalyst_board(self):
        st.markdown("## üì∞ Single-Stock & Sector Catalyst Board")
        for it in self.provider.get_catalyst_board():
            with st.expander(f"{it['title']} ‚Äî {it['summary']}"):
                st.write(it['details'])
                st.write(f"**Plan:** {it['plan']}")

    # ---------- Section 5: Session Map ----------
    def render_session_map(self):
        st.markdown("## üó∫Ô∏è Session Map (Roadmap for Today)")
        for i in self.provider.get_session_map():
            st.markdown(f"- **{i['window']}**: {i['text']}")

    # ---------- Section 6: VectorVest Alt Color Guard ----------
    def render_color_guard_alt(self):
        st.markdown("## üü©üü®üü• VectorVest-Style Color Guard (Alt)")
        cg = self.provider.get_color_guard_inputs()
        a, b, c = st.columns(3)
        a.markdown(color_block("Price Trend", {"green":"#16a34a","yellow":"#f59e0b","red":"#dc2626"}[cg['price_signal']]), unsafe_allow_html=True)
        b.markdown(color_block("Breadth Trend", {"green":"#16a34a","yellow":"#f59e0b","red":"#dc2626"}[cg['breadth_signal']]), unsafe_allow_html=True)
        c.markdown(color_block("Risk / VIX", {"green":"#16a34a","yellow":"#f59e0b","red":"#dc2626"}[cg['risk_signal']]), unsafe_allow_html=True)
        st.caption("Green=favorable ¬∑ Yellow=neutral/choppy ¬∑ Red=risk-off.")

    # ---------- NEW Section: Economic Calendar (Next 7 Days) ----------
    def render_econ_calendar(self):
        st.markdown("## üìÖ Economic Calendar (Next 7 Days)")

        # prefer snapshots file generated by your weekly workflow
        path = "snapshots/econ_week.json"
        data = None

        if os.path.exists(path):
            try:
                with open(path, "r", encoding="utf-8") as f:
                    data = json.load(f)
            except Exception as e:
                st.error(f"Could not read econ_week.json: {e}")
                return

        # Support both styles:
        # 1) plain array: [ {date, region, event, importance}, ... ]
        # 2) wrapped dict: { generated_utc, window:{start,end}, events:[...] }
        events = []
        window_str = ""
        if isinstance(data, dict):
            events = data.get("events") or []
            w = data.get("window") or {}
            if "start" in w and "end" in w:
                window_str = f"**Window:** {w['start']} ‚Üí {w['end']}"
        elif isinstance(data, list):
            events = data

        if window_str:
            st.caption(window_str)

        if not events:
            st.info("No events scheduled in this window or the calendar hasn‚Äôt been generated yet.")
            st.caption("Tip: run the 'Econ Calendar (Weekly)' workflow, or add events to config/econ_calendar.yaml.")
            return

        # Render events with a colored importance chip
        for e in events:
            date_ = e.get("date", "")
            region = e.get("region", "")
            event = e.get("event", "")
            imp = (e.get("importance") or "").lower()
            color = {"low":"#22c55e", "medium":"#f59e0b", "high":"#dc2626"}.get(imp, "#6b7280")

            st.markdown(
                f"<div style='padding:8px 10px;margin-bottom:6px;border-radius:10px;"
                f"border:1px solid {color}55;background:{color}15;'>"
                f"<div style='display:flex;justify-content:space-between;align-items:center;'>"
                f"<b>{date_} &nbsp;[{region}]</b>"
                f"<span style='color:{color};font-weight:700;text-transform:uppercase'>{imp or 'n/a'}</span>"
                f"</div>"
                f"<div style='margin-top:4px'>{event}</div>"
                f"</div>",
                unsafe_allow_html=True
            )

    
    # ---------- Section: VectorVest Metrics Snapshot ----------
    def render_vectorvest_metrics(self):
        st.markdown("## üìä VectorVest Metrics (Watchlist Snapshot)")
        # Base watchlist (if available)
        base = None
        base_path = os.path.join("data","screener.csv")
        if os.path.exists(base_path):
            try:
                base = pd.read_csv(base_path)
            except Exception:
                base = None

        # Load server cache of VV signals, or fallback to empty
        vv_json = os.path.join("vault","cache","vectorvest_signals.json")
        metrics = pd.DataFrame()
        if os.path.exists(vv_json):
            try:
                data = json.load(open(vv_json, "r", encoding="utf-8"))
                metrics = pd.DataFrame(data.get("signals", []))
            except Exception:
                pass

        try:
            from .vectorvest_utils import compute_vv_columns, merge_metrics
        except Exception:
            compute_vv_columns = lambda d, *_: d
            def merge_metrics(a,b): return a

        # Normalize & compute vst
        metrics = compute_vv_columns(metrics, os.path.join("modules","rules","_vega_scores.yaml"))

        if base is not None:
            # Show only tickers on our screener list, merged with metrics
            df = merge_metrics(base, metrics)
        else:
            df = metrics

        if df is None or df.empty:
            st.info("No VectorVest metrics available yet. They will appear once the server cache populates or screener.csv contains RT/RS/RV/CI/EPS/Growth/Sales Growth columns.")
            return

        # Select core columns if present
        core_cols = [c for c in ["symbol","name","price","rt","rv","rs","vst","ci","eps","growth","sales_growth","grade","decision"] if c in df.columns]
                # Optional sparklines
        try:
            spark = self.build_vv_sparklines(df)
            if spark is not None and not spark.empty:
                df = df.merge(spark, on='symbol', how='left')
        except Exception:
            pass
        disp_cols = core_cols + [c for c in ['vst_spark','eps_spark','growth_spark','sales_growth_spark'] if c in df.columns]
        try:
            from streamlit import column_config
            st.dataframe(
                df[disp_cols],
                use_container_width=True,
                column_config={
                    'vst_spark': column_config.ImageColumn('VST'),
                    'eps_spark': column_config.ImageColumn('EPS'),
                    'growth_spark': column_config.ImageColumn('Growth'),
                    'sales_growth_spark': column_config.ImageColumn('Sales Growth'),
                }
            )
        # DOWNLOAD: VV table CSV
        try:
            import io
            csv = df[core_cols].to_csv(index=False).encode('utf-8')
            st.download_button('‚¨áÔ∏è Download VV Table (CSV)', data=csv, file_name='vectorvest_metrics.csv', mime='text/csv')
        except Exception:
            pass
        # VST badge column (formatted)
        if 'vst' in df.columns:
            df['vst_badge'] = df['vst'].map(lambda x: f"{x:.2f}" if pd.notnull(x) else '')
        except Exception:
            st.dataframe(df[core_cols], use_container_width=True)
        # DOWNLOAD: VV table CSV
        try:
            import io
            csv = df[core_cols].to_csv(index=False).encode('utf-8')
            st.download_button('‚¨áÔ∏è Download VV Table (CSV)', data=csv, file_name='vectorvest_metrics.csv', mime='text/csv')
        except Exception:
            pass
        # VST badge column (formatted)
        if 'vst' in df.columns:
            df['vst_badge'] = df['vst'].map(lambda x: f"{x:.2f}" if pd.notnull(x) else '')
        self.render_vst_preview()
    
# ---------- Section 7: Final Risk Overlay ----------
    def render_final_risk_overlay(self):
        fr = self.provider.get_final_risk_overlay()
        st.markdown("## üõ°Ô∏è Final Risk Overlay & Action Plan")
        st.markdown("### Hedge Triggers"); st.markdown(f"- Primary: {fr['primary']}"); st.markdown(f"- Secondary: {fr['secondary']}")
        st.markdown("### FX Guardrails"); st.markdown(f"- {fr['fx']}")
        st.markdown("### Tactical Implications"); [st.markdown(f"- {t}") for t in fr['tactical']]
        st.markdown("### Trade Now vs Wait"); st.dataframe(pd.DataFrame(fr['trade_board']), use_container_width=True)
        self.render_snapshot_button()


    def render_vst_preview(self):
        st.markdown("### VST Trend Preview")
        try:
            from components.vst_trend import render_vst_trend
        except Exception:
            st.caption("VST trend component unavailable.")
            return
        # Populate select from merged metrics if available
        options = []
        vv_json = os.path.join("vault","cache","vectorvest_signals.json")
        if os.path.exists(vv_json):
            try:
                data = json.load(open(vv_json, "r", encoding="utf-8"))
                options = [i.get("symbol","") for i in data.get("signals", []) if i.get("symbol")]
            except Exception:
                pass
        if not options and os.path.exists(os.path.join("data","screener.csv")):
            import pandas as pd
            try:
                df = pd.read_csv(os.path.join("data","screener.csv"))
                if "symbol" in df.columns:
                    options = list(df["symbol"].dropna().unique())
            except Exception:
                pass
        if not options:
            st.caption("Add symbols to `vault/cache/vectorvest_signals.json` or `data/screener.csv` to preview VST trends.")
            return
        sym = st.selectbox("Select symbol", sorted(set(options)))
        if sym:
            render_vst_trend(sym)
    

    def build_vv_sparklines(self, df, metrics=("vst","eps","growth","sales_growth")):
        import pandas as pd, os
        from components.sparklines import save_sparkline
        # attempt to load per-symbol timeseries CSVs and render PNGs
        rows = []
        for _, row in (df if isinstance(df, pd.DataFrame) else pd.DataFrame(df)).iterrows():
            sym = row.get("symbol")
            if not sym: 
                continue
            record = {"symbol": sym}
            for m in metrics:
                # load series
                base = os.path.join("vault","timeseries","vv")
                fn = {"vst": f"{sym}_spark.csv", "eps": f"{sym}_eps_spark.csv", "growth": f"{sym}_growth_spark.csv", "sales_growth": f"{sym}_sales_growth_spark.csv"}
                # Backward-compat: also accept main CSV names (we will just rename value column)
                fallback = {
                    "vst": f"{sym}.csv",
                    "eps": f"{sym}_eps.csv",
                    "growth": f"{sym}_growth.csv",
                    "sales_growth": f"{sym}_sales_growth.csv"
                }
                import pandas as pd
                path = os.path.join(base, fn[m])
                if not os.path.exists(path):
                    path = os.path.join(base, fallback[m])
                if not os.path.exists(path):
                    continue
                try:
                    tdf = pd.read_csv(path)
                    tdf.columns = [c.lower() for c in tdf.columns]
                    val_col = m if m in tdf.columns else ("vst" if "vst" in tdf.columns else "value")
                    if "date" not in tdf.columns or val_col not in tdf.columns:
                        continue
                    tdf = tdf.tail(26)  # 26w preview
                    tdf = tdf.rename(columns={val_col:"value"})
                    p = save_sparkline(sym, m, tdf[["date","value"]])
                    if p:
                        record[f"{m}_spark"] = p
                except Exception:
                    pass
            rows.append(record)
        return pd.DataFrame(rows) if rows else None
    


    # ---------- Utility: One-Click Snapshot ----------
    def render_snapshot_button(self):
        from components.snapshot_export import snapshot_button
        snapshot_button("morning_report")
