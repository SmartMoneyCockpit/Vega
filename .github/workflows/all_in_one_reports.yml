name: All-in-One Reports, Email, Monthly Release & Cleanup

on:
  workflow_dispatch:
    inputs:
      force_monthly_release:
        description: 'Force-create a Monthly Release on this run (even if not 1st of month)'
        required: false
        default: 'false'
      run_na:
        description: 'Run NA job'
        type: boolean
        default: true
      run_eu:
        description: 'Run Europe job'
        type: boolean
        default: true
      run_apac:
        description: 'Run APAC job'
        type: boolean
        default: true
      email_subject:
        description: 'Override email subject'
        type: string
        default: ''
  schedule:
    - cron: '55 14 * * 1-5'
    - cron: '55 15 * * 1-5'
    - cron: '0 16 * * 6'
    - cron: '0 16 1 * *'

permissions:
  contents: write

concurrency:
  group: all-in-one-reports
  cancel-in-progress: true

env:
  DEFAULT_EMAIL_SUBJECT: "Reports - All Regions (Run #${{ github.run_number }})"
  DEFAULT_EMAIL_BODY: |
    Your combined bundle is attached (or linked if too large).
    Repo: ${{ github.repository }}
    Run:  ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}

jobs:
  regions:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        include:
          - region: NA
            region_lc: na
            timezone: America/Los_Angeles
          - region: EU
            region_lc: europe
            timezone: Europe/London
          - region: APAC
            region_lc: apac
            timezone: America/Los_Angeles
    env:
      REGION: ${{ matrix.region }}
      REGION_LC: ${{ matrix.region_lc }}
      TZ: ${{ matrix.timezone }}
    steps:
      - uses: actions/checkout@v4

      - name: Gate this region based on dispatch inputs
        id: gate
        shell: bash
        env:
          RUN_NA:  ${{ (github.event_name != 'workflow_dispatch') || inputs.run_na }}
          RUN_EU:  ${{ (github.event_name != 'workflow_dispatch') || inputs.run_eu }}
          RUN_AP:  ${{ (github.event_name != 'workflow_dispatch') || inputs.run_apac }}
          REGION:  ${{ matrix.region }}
        run: |
          set -e
          en=false
          case "$REGION" in
            NA)   [[ "$RUN_NA" == "true" ]] && en=true ;;
            EU)   [[ "$RUN_EU" == "true" ]] && en=true ;;
            APAC) [[ "$RUN_AP" == "true" ]] && en=true ;;
          esac
          echo "enabled=$en" >> "$GITHUB_OUTPUT"
          echo "Region=$REGION enabled? $en"

      - uses: actions/setup-python@v5
        if: steps.gate.outputs.enabled == 'true'
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install optional deps (yfinance, pandas)
        if: steps.gate.outputs.enabled == 'true'
        run: |
          python -m pip install --upgrade pip
          pip install -q yfinance pandas

      - name: Run Morning Report (per-region)
        if: steps.gate.outputs.enabled == 'true'
        shell: bash
        run: |
          set -e
          OUT="output/morning_report_${REGION_LC}.md"
          mkdir -p output
          if [[ -f "scripts/morning_report_${REGION_LC}.py" ]]; then
            python "scripts/morning_report_${REGION_LC}.py" --tz "${TZ}" --out "${OUT}" || true
          elif [[ -f "scripts/morning_report.py" ]]; then
            python scripts/morning_report.py --tz "${TZ}" --out "${OUT}" || true
          fi
          if [[ ! -s "${OUT}" ]]; then
            for CAND in               "reports/morning_report_${REGION_LC}.md"               "reports/${REGION_LC}/morning_report.md"               "reports/morning_report.md"               "output/morning_report.md" ; do
              [[ -s "${CAND}" ]] && { cp -f "${CAND}" "${OUT}"; break; }
            done
          fi
          [[ -s "${OUT}" ]] || echo "# Morning Report ${REGION} (placeholder)" > "${OUT}"

      - name: Upload Morning Report
        if: steps.gate.outputs.enabled == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: morning-report-${{ env.REGION }}
          path: output/morning_report_${{ env.REGION_LC }}.md
          retention-days: 14
          compression-level: 6

      - name: Run Color Guard (per-region)
        if: steps.gate.outputs.enabled == 'true'
        shell: bash
        run: |
          set -e
          mkdir -p alerts output/color_guard
          FILE="scripts/color_guard_${REGION_LC}.py"
          if [[ -f "${FILE}" ]]; then
            python "${FILE}" || true
          elif [[ -f "scripts/color_guard.py" ]]; then
            python scripts/color_guard.py || true
          fi
          OUT="alerts/color_guard_${REGION_LC}.json"
          if [[ ! -s "${OUT}" ]]; then
            for CAND in               "guards/color_guard_${REGION_LC}.json"               "output/color_guard/color_guard_${REGION_LC}.json"               "output/color_guard.json" ; do
              [[ -s "${CAND}" ]] && { cp -f "${CAND}" "${OUT}"; break; }
            done
          fi
          [[ -s "${OUT}" ]] || echo '{"region":"'"${REGION}"'","status":"ok","note":"placeholder"}' > "${OUT}"

      - name: Upload Color Guard
        if: steps.gate.outputs.enabled == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: color-guard-${{ env.REGION }}
          path: |
            output/color_guard/**
            alerts/color_guard_${{ env.REGION_LC }}.json
          retention-days: 14
          compression-level: 6

      - name: Run Econ Calendar (per-region)
        if: steps.gate.outputs.enabled == 'true'
        shell: bash
        run: |
          set -e
          mkdir -p assets output/econ_calendar
          FILE="scripts/econ_calendar_${REGION_LC}.py"
          if [[ -f "${FILE}" ]]; then
            python "${FILE}" || true
          elif [[ -f "scripts/econ_calendar.py" ]]; then
            python scripts/econ_calendar.py || true
          fi
          OUT="assets/econ_calendar_${REGION_LC}.csv"
          if [[ ! -s "${OUT}" ]]; then
            for CAND in               "reports/econ_calendar_${REGION_LC}.csv"               "reports/${REGION_LC}/econ_calendar.csv"               "output/econ_calendar/econ_calendar_${REGION_LC}.csv" ; do
              [[ -s "${CAND}" ]] && { cp -f "${CAND}" "${OUT}"; break; }
            done
          fi
          if [[ ! -s "${OUT}" ]]; then
            echo "date,time_tz,region,event,impact" > "${OUT}"
            echo "$(date +%F),08:30,${TZ},Placeholder,-" >> "${OUT}"
          fi
          cp -f "${OUT}" "output/econ_calendar/" 2>/dev/null || true

      - name: Upload Econ Calendar
        if: steps.gate.outputs.enabled == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: econ-calendar-${{ env.REGION }}
          path: |
            output/econ_calendar/**
            assets/econ_calendar_${{ env.REGION_LC }}.csv
          retention-days: 14
          compression-level: 6

      - name: Run Uptime Ping
        if: steps.gate.outputs.enabled == 'true'
        shell: bash
        run: |
          mkdir -p output/uptime_ping
          if [[ -f scripts/uptime_ping.py ]]; then
            python scripts/uptime_ping.py
          else
            echo "pong $(date -u +'%F %T')Z" > output/uptime_ping/ping.txt
          fi

      - name: Upload Uptime Ping
        if: steps.gate.outputs.enabled == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: uptime-ping-${{ env.REGION }}
          path: output/uptime_ping/**
          retention-days: 14
          compression-level: 6

      - name: Create region zip
        if: steps.gate.outputs.enabled == 'true'
        shell: bash
        run: |
          set -e
          mkdir -p pack
          cp -rf alerts assets output pack/ 2>/dev/null || true
          ( cd pack && zip -r ../report_${REGION}.zip . || true )

      - name: Upload region zip
        if: steps.gate.outputs.enabled == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: report-${{ env.REGION }}
          path: report_${{ env.REGION }}.zip
          retention-days: 14

  aggregate:
    needs: regions
    runs-on: ubuntu-latest
    steps:
      - name: Download all artifacts from this run
        uses: actions/download-artifact@v4
        with:
          path: artifacts
          merge-multiple: true

      - name: Build global_summary.md and combined zip
        shell: bash
        run: |
          set -e
          mkdir -p summary
          MR_NA="$(find artifacts -type f -iname 'morning_report_na.md' -print -quit || true)"
          MR_EU="$(find artifacts -type f -iname 'morning_report_europe.md' -print -quit || true)"
          MR_AP="$(find artifacts -type f -iname 'morning_report_apac.md' -print -quit || true)"
          {
            echo "# Global Summary"
            echo
            if [[ -s "$MR_NA" ]]; then echo "## NA"; echo; cat "$MR_NA"; echo; fi
            if [[ -s "$MR_EU" ]]; then echo; echo "## Europe"; echo; cat "$MR_EU"; echo; fi
            if [[ -s "$MR_AP" ]]; then echo; echo "## APAC"; echo; cat "$MR_AP"; echo; fi
          } > summary/global_summary.md
          zip -r reports-all-regions.zip artifacts summary/global_summary.md

      - name: Upload combined bundle
        uses: actions/upload-artifact@v4
        with:
          name: reports-all-regions
          path: reports-all-regions.zip
          retention-days: 14

  commit_snapshots:
    name: Commit snapshot CSVs into repo
    needs: regions
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Download all artifacts from region jobs
        uses: actions/download-artifact@v4
        with:
          path: out
          merge-multiple: true

      - name: Stage CSVs to expected repo paths
        shell: bash
        run: |
          set -e
          mkdir -p data/snapshots/na data/snapshots/eu data/snapshots/apac

          # Preferred direct names (adjust if your scripts use different names)
          cp -f out/na_index_snapshot.csv   data/snapshots/na/index_snapshot.csv   2>/dev/null || true
          cp -f out/eu_index_snapshot.csv   data/snapshots/eu/index_snapshot.csv   2>/dev/null || true
          cp -f out/apac_index_snapshot.csv data/snapshots/apac/index_snapshot.csv 2>/dev/null || true

          # QUICK FIX (ALIAS): map econ-calendar artifacts (with or without extension) into index_snapshot.csv
          cp -f out/econ-calendar-NA*    data/snapshots/na/index_snapshot.csv   2>/dev/null || true
          cp -f out/econ-calendar-EU*    data/snapshots/eu/index_snapshot.csv   2>/dev/null || true
          cp -f out/econ-calendar-APAC*  data/snapshots/apac/index_snapshot.csv 2>/dev/null || true

          # Fallback: discover by pattern if still missing
          [[ -s data/snapshots/na/index_snapshot.csv ]] ||             (f="$(find out -maxdepth 2 -type f -iname '*na*index*snapshot*.csv' -o -iname 'index_snapshot_na.csv' -o -iname '*econ*na*' -print -quit)";              [[ -n "$f" ]] && cp -f "$f" data/snapshots/na/index_snapshot.csv || true)

          [[ -s data/snapshots/eu/index_snapshot.csv ]] ||             (f="$(find out -maxdepth 2 -type f -iname '*eu*index*snapshot*.csv' -o -iname '*europe*index*snapshot*.csv' -o -iname 'index_snapshot_eu.csv' -o -iname '*econ*eu*' -print -quit)";              [[ -n "$f" ]] && cp -f "$f" data/snapshots/eu/index_snapshot.csv || true)

          [[ -s data/snapshots/apac/index_snapshot.csv ]] ||             (f="$(find out -maxdepth 2 -type f -iname '*apac*index*snapshot*.csv' -o -iname 'index_snapshot_apac.csv' -o -iname '*econ*apac*' -print -quit)";              [[ -n "$f" ]] && cp -f "$f" data/snapshots/apac/index_snapshot.csv || true)

      - name: Commit & push if there are changes
        shell: bash
        run: |
          set -e
          if [ -n "$(git status --porcelain data/snapshots)" ]; then
            git config user.name  "github-actions[bot]"
            git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
            git add data/snapshots
            git commit -m "chore(snapshot): update NA/EU/APAC CSVs [skip ci]"
            git push
          else
            echo "No snapshot changes to commit."
          fi

  email_bundle:
    needs: aggregate
    runs-on: ubuntu-latest
    environment: Vega
    steps:
      - name: Download combined bundle
        uses: actions/download-artifact@v4
        with:
          name: reports-all-regions
          path: dl

      - name: Normalize and show FROM/TO
        id: norm
        shell: bash
        env:
          FROM_VAR: ${{ vars.SENDGRID_FROM || vars.ALERTS_FROM }}
          TO_VAR:   ${{ vars.SENDGRID_TO   || vars.ALERTS_TO   }}
        run: |
          set -e
          FROM=$(printf '%s' "$FROM_VAR" | tr -d '\r' | sed -e 's/^[[:space:]]*//' -e 's/[[:space:]]*$//')
          TO=$(printf '%s' "$TO_VAR" | tr -d '\r' | sed -e 's/^[[:space:]]*//' -e 's/[[:space:]]*$//')
          echo "from=$FROM" >> "$GITHUB_OUTPUT"
          echo "to=$TO" >> "$GITHUB_OUTPUT"
          echo "Using FROM=$FROM TO=$TO"

      - name: Check attachment size
        id: size
        shell: bash
        run: |
          set -e
          FILE="dl/reports-all-regions.zip"
          if [[ ! -s "$FILE" ]]; then
            echo "::warning::No combined bundle found; nothing to email."
            echo "oversize=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          BYTES=$(stat -c%s "$FILE" 2>/dev/null || stat -f%z "$FILE")
          echo "bytes=$BYTES" >> "$GITHUB_OUTPUT"
          if [ "$BYTES" > 25000000 ]; then
            echo "::warning::Attachment exceeds 25MB; sending without attachment."
            echo "oversize=true" >> "$GITHUB_OUTPUT"
          else
            echo "oversize=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Email via SendGrid (primary)
        id: sg
        env:
          SG_KEY: ${{ secrets.SENDGRID_API_KEY }}
          FROM:   ${{ steps.norm.outputs.from }}
          TO:     ${{ steps.norm.outputs.to }}
          SUBJECT_INPUT: ${{ github.event.inputs.email_subject }}
          DEFAULT_SUBJECT: ${{ env.DEFAULT_EMAIL_SUBJECT }}
          BODY_DEFAULT: ${{ env.DEFAULT_EMAIL_BODY }}
        shell: bash
        run: |
          set -e
          if [[ -z "${SG_KEY:-}" || -z "${FROM:-}" || -z "${TO:-}" ]]; then
            echo "no_sg=true" >> "$GITHUB_OUTPUT"
            echo "::warning::SendGrid not configured; skipping primary."
            exit 0
          fi
          FILE="dl/reports-all-regions.zip"
          SUBJECT="${SUBJECT_INPUT:-$DEFAULT_SUBJECT}"
          printf '%s' "$BODY_DEFAULT" > body.txt

          if [[ "${{ steps.size.outputs.oversize }}" == "true" || ! -s "$FILE" ]]; then
            jq -n --arg from "$FROM" --arg to "$TO" --arg subject "$SUBJECT" --rawfile content body.txt               '{personalizations:[{to:[{email:$to}]}],from:{email:$from},subject:$subject,content:[{type:"text/plain",value:$content}]}' > payload.json
          else
            base64 -w 0 "$FILE" > b64.txt
            jq -n --arg from "$FROM" --arg to "$TO" --arg subject "$SUBJECT" --rawfile content body.txt --rawfile b64 b64.txt               '{personalizations:[{to:[{email:$to}]}],from:{email:$from},subject:$subject,content:[{type:"text/plain",value:$content}],attachments:[{content:$b64,type:"application/zip",filename:"reports-all-regions.zip"}]}' > payload.json
          fi

          CODE=$(curl -sS -o response.json -w "%{http_code}" -X POST https://api.sendgrid.com/v3/mail/send -H "Authorization: Bearer ${SG_KEY}" -H "Content-Type: application/json" --data @payload.json)
          echo "http_code=$CODE" >> "$GITHUB_OUTPUT"
          echo "=== SendGrid response (HTTP $CODE) ==="
          cat response.json || true
          if [ "$CODE" != "202" ]; then
            echo "::error::SendGrid returned HTTP $CODE"
            exit 1
          fi

      - name: Fallback via Gmail SMTP (runs if SG skipped/failed)
        if: failure() || steps.sg.outputs.no_sg == 'true'
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 465
          secure: true
          username: ${{ secrets.MAIL_USER }}
          password: ${{ secrets.MAIL_APP_PASSWORD }}
          subject: ${{ github.event.inputs.email_subject || env.DEFAULT_EMAIL_SUBJECT }}
          to: ${{ secrets.MAIL_TO }}
          from: ${{ secrets.MAIL_USER }}
          body: ${{ env.DEFAULT_EMAIL_BODY }}
          attachments: dl/reports-all-regions.zip

  monthly_release:
    needs: aggregate
    runs-on: ubuntu-latest
    steps:
      - name: Decide whether to create release
        id: gate
        shell: bash
        run: |
          FORCE="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.force_monthly_release == 'true' }}"
          DOM="$(date -u +%d)"
          if [[ "$FORCE" == "true" ]]; then
            echo "run_release=true" >> "$GITHUB_OUTPUT"
          elif [[ "${GITHUB_EVENT_NAME}" == "schedule" && "$DOM" == "01" ]]; then
            echo "run_release=true" >> "$GITHUB_OUTPUT"
          else
            echo "run_release=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Download combined bundle
        if: steps.gate.outputs.run_release == 'true'
        uses: actions/download-artifact@v4
        with:
          name: reports-all-regions
          path: dl

      - name: Download per-region zips
        if: steps.gate.outputs.run_release == 'true'
        uses: actions/download-artifact@v4
        with:
          pattern: report-*
          path: dl
          merge-multiple: true

      - name: Compute release meta
        if: steps.gate.outputs.run_release == 'true'
        id: meta
        shell: bash
        run: |
          YMD="$(date -u +%Y-%m-%d)"; YM="$(date -u +%Y-%m)"
          echo "ymd=$YMD" >> "$GITHUB_OUTPUT"; echo "ym=$YM" >> "$GITHUB_OUTPUT"

      - name: Create GitHub Release (monthly)
        if: steps.gate.outputs.run_release == 'true'
        uses: softprops/action-gh-release@v2
        with:
          tag_name: monthly-${{ steps.meta.outputs.ym }}
          name: Monthly Reports - ${{ steps.meta.outputs.ym }}
          body: |
            Automated monthly export for ${{ steps.meta.outputs.ymd }}.
            Includes: reports-all-regions.zip and per-region bundles (if present).
          files: |
            dl/reports-all-regions.zip
            dl/report_*.zip

  cleanup:
    needs: aggregate
    runs-on: ubuntu-latest
    permissions:
      actions: write
      contents: read
    steps:
      - name: Check if Saturday (UTC) on schedule
        id: daycheck
        shell: bash
        run: |
          if [[ "${GITHUB_EVENT_NAME}" != "schedule" ]]; then
            echo "run_cleanup=false" >> "$GITHUB_OUTPUT"; exit 0; fi
          DOW="$(date -u +%u)"
          [[ "$DOW" == "6" ]] && echo "run_cleanup=true" >> "$GITHUB_OUTPUT" || echo "run_cleanup=false" >> "$GITHUB_OUTPUT"

      - name: Delete artifacts older than 14 days
        if: steps.daycheck.outputs.run_cleanup == 'true'
        uses: actions/github-script@v7
        env:
          RETAIN_DAYS: '14'
        with:
          script: |
            const owner = context.repo.owner, repo = context.repo.repo;
            const days = parseInt(process.env.RETAIN_DAYS || '14', 10);
            const cutoff = Date.now() - days*24*60*60*1000;
            let deleted=0, kept=0;
            for await (const page of github.paginate.iterator(
              github.rest.actions.listArtifactsForRepo, { owner, repo, per_page: 100 })) {
              for (const a of page.data) {
                const created = Date.parse(a.created_at);
                if (!a.expired && created < cutoff) {
                  await github.rest.actions.deleteArtifact({ owner, repo, artifact_id: a.id });
                  deleted++;
                } else { kept++; }
              }
            }
            core.summary.addHeading('Artifact Cleanup')
              .addRaw(`Deleted: ${deleted} • Kept: ${kept} • Cutoff: ${new Date(cutoff).toISOString()}`)
              .write();

      - name: Delete old workflow runs (keep 20, only if >30 days old)
        if: steps.daycheck.outputs.run_cleanup == 'true'
        uses: actions/github-script@v7
        env:
          KEEP_PER_WF: '20'
          RUNS_MAX_AGE_DAYS: '30'
        with:
          script: |
            const owner = context.repo.owner, repo = context.repo.repo;
            const keep = parseInt(process.env.KEEP_PER_WF || '20', 10);
            const maxAgeDays = parseInt(process.env.RUNS_MAX_AGE_DAYS || '30', 10);
            const cutoff = Date.now() - maxAgeDays*24*60*60*1000;
            const runs = await github.paginate(
              github.rest.actions.listWorkflowRunsForRepo, { owner, repo, per_page: 100, status: 'completed' });
            const groups = {};
            for (const r of runs) { const key = `${r.workflow_id}:${r.name || ''}`; (groups[key] ||= []).push(r); }
            let deleted=0, kept=0;
            for (const key of Object.keys(groups)) {
              const list = groups[key].sort((a,b)=> new Date(b.created_at) - new Date(a.created_at));
              for (const [i, run] of list.entries()) {
                const isOld = Date.parse(run.created_at) < cutoff;
                if (i >= keep && isOld) {
                  await github.rest.actions.deleteWorkflowRun({ owner, repo, run_id: run.id });
                  deleted++;
                } else { kept++; }
              }
            }
            core.summary.addHeading('Run Cleanup')
              .addRaw(`Deleted runs: ${deleted} • Kept: ${kept} • Cutoff: ${new Date(cutoff).toISOString()} • Keep per WF: ${keep}`)
              .write();
