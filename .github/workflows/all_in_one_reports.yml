name: All-in-One Reports, Email, Monthly Release & Cleanup

on:
  workflow_dispatch:
    inputs:
      force_monthly_release:
        description: 'Force-create a Monthly Release on this run (even if not 1st of month)'
        required: false
        default: 'false'
      # Optional manual toggles (default ON)
      run_na:
        description: 'Run NA job'
        type: boolean
        default: true
      run_eu:
        description: 'Run Europe job'
        type: boolean
        default: true
      run_apac:
        description: 'Run APAC job'
        type: boolean
        default: true
      email_subject:
        description: 'Override email subject'
        type: string
        default: ''
  schedule:
    # Weekday auto-runs ~07:55–08:55 AM PT
    - cron: '55 14 * * 1-5'
    - cron: '55 15 * * 1-5'
    # Saturday cleanup ~09:00 AM PT (16:00 UTC)
    - cron: '0 16 * * 6'
    # 1st of month ~09:00 AM PT for monthly release
    - cron: '0 16 1 * *'

permissions:
  contents: write

concurrency:
  group: all-in-one-reports
  cancel-in-progress: true

env:
  DEFAULT_EMAIL_SUBJECT: "Reports - All Regions (Run #${{ github.run_number }})"
  DEFAULT_EMAIL_BODY: |
    Your combined bundle is attached (or linked if too large).
    Repo: ${{ github.repository }}
    Run:  ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}

jobs:
  regions:
    if: ${{ !(github.event_name == 'workflow_dispatch' && (
            (matrix.region == 'NA'   && !inputs.run_na) ||
            (matrix.region == 'EU'   && !inputs.run_eu) ||
            (matrix.region == 'APAC' && !inputs.run_apac)
          )) }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        include:
          - region: NA
            region_lc: na
            timezone: America/Los_Angeles
          - region: EU
            region_lc: europe
            timezone: Europe/London
          - region: APAC
            region_lc: apac
            timezone: America/Los_Angeles
    env:
      REGION: ${{ matrix.region }}
      REGION_LC: ${{ matrix.region_lc }}
      TZ: ${{ matrix.timezone }}
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install optional deps (yfinance, pandas)
        run: |
          python -m pip install --upgrade pip
          pip install -q yfinance pandas

      - name: Run Morning Report (per-region)
        shell: bash
        run: |
          set -e
          OUT="output/morning_report_${REGION_LC}.md"
          mkdir -p output
          if [[ -f "scripts/morning_report_${REGION_LC}.py" ]]; then
            python "scripts/morning_report_${REGION_LC}.py" --tz "${TZ}" --out "${OUT}" || true
          elif [[ -f "scripts/morning_report.py" ]]; then
            python scripts/morning_report.py --tz "${TZ}" --out "${OUT}" || true
          fi
          if [[ ! -s "${OUT}" ]]; then
            for CAND in \
              "reports/morning_report_${REGION_LC}.md" \
              "reports/${REGION_LC}/morning_report.md" \
              "reports/morning_report.md" \
              "output/morning_report.md" ; do
              [[ -s "${CAND}" ]] && { cp -f "${CAND}" "${OUT}"; break; }
            done
          fi
          [[ -s "${OUT}" ]] || echo "# Morning Report ${REGION} (placeholder)" > "${OUT}"

      - name: Upload Morning Report
        uses: actions/upload-artifact@v4
        with:
          name: morning-report-${{ env.REGION }}
          path: output/morning_report_${{ env.REGION_LC }}.md
          retention-days: 14
          compression-level: 6

      - name: Run Color Guard (per-region)
        shell: bash
        run: |
          set -e
          mkdir -p alerts output/color_guard
          FILE="scripts/color_guard_${REGION_LC}.py"
          if [[ -f "${FILE}" ]]; then
            python "${FILE}" || true
          elif [[ -f "scripts/color_guard.py" ]]; then
            python scripts/color_guard.py || true
          fi
          OUT="alerts/color_guard_${REGION_LC}.json"
          if [[ ! -s "${OUT}" ]]; then
            for CAND in \
              "guards/color_guard_${REGION_LC}.json" \
              "output/color_guard/color_guard_${REGION_LC}.json" \
              "output/color_guard.json" ; do
              [[ -s "${CAND}" ]] && { cp -f "${CAND}" "${OUT}"; break; }
            done
          fi
          [[ -s "${OUT}" ]] || echo '{"region":"'"${REGION}"'","status":"ok","note":"placeholder"}' > "${OUT}"

      - name: Upload Color Guard
        uses: actions/upload-artifact@v4
        with:
          name: color-guard-${{ env.REGION }}
          path: |
            output/color_guard/**
            alerts/color_guard_${{ env.REGION_LC }}.json
          retention-days: 14
          compression-level: 6

      - name: Run Econ Calendar (per-region)
        shell: bash
        run: |
          set -e
          mkdir -p assets output/econ_calendar
          FILE="scripts/econ_calendar_${REGION_LC}.py"
          if [[ -f "${FILE}" ]]; then
            python "${FILE}" || true
          elif [[ -f "scripts/econ_calendar.py" ]]; then
            python scripts/econ_calendar.py || true
          fi
          OUT="assets/econ_calendar_${REGION_LC}.csv"
          if [[ ! -s "${OUT}" ]]; then
            for CAND in \
              "reports/econ_calendar_${REGION_LC}.csv" \
              "reports/${REGION_LC}/econ_calendar.csv" \
              "output/econ_calendar/econ_calendar_${REGION_LC}.csv" ; do
              [[ -s "${CAND}" ]] && { cp -f "${CAND}" "${OUT}"; break; }
            done
          fi
          if [[ ! -s "${OUT}" ]]; then
            echo "date,time_tz,region,event,impact" > "${OUT}"
            echo "$(date +%F),08:30,${TZ},Placeholder,-" >> "${OUT}"
          fi
          cp -f "${OUT}" "output/econ_calendar/" 2>/dev/null || true

      - name: Upload Econ Calendar
        uses: actions/upload-artifact@v4
        with:
          name: econ-calendar-${{ env.REGION }}
          path: |
            output/econ_calendar/**
            assets/econ_calendar_${{ env.REGION_LC }}.csv
          retention-days: 14
          compression-level: 6

      - name: Run Uptime Ping
        shell: bash
        run: |
          mkdir -p output/uptime_ping
          if [[ -f scripts/uptime_ping.py ]]; then
            python scripts/uptime_ping.py
          else
            echo "pong $(date -u +'%F %T')Z" > output/uptime_ping/ping.txt
          fi

      - name: Upload Uptime Ping
        uses: actions/upload-artifact@v4
        with:
          name: uptime-ping-${{ env.REGION }}
          path: output/uptime_ping/**
          retention-days: 14
          compression-level: 6

      - name: Create region zip
        shell: bash
        run: |
          set -e
          mkdir -p pack
          cp -rf alerts assets output pack/ 2>/dev/null || true
          ( cd pack && zip -r ../report_${REGION}.zip . || true )

      - name: Upload region zip
        uses: actions/upload-artifact@v4
        with:
          name: report-${{ env.REGION }}
          path: report_${{ env.REGION }}.zip
          retention-days: 14

  aggregate:
    needs: regions
    runs-on: ubuntu-latest
    steps:
      - name: Download all artifacts from this run
        uses: actions/download-artifact@v4
        with:
          path: artifacts
          merge-multiple: true

      - name: Build global_summary.md and combined zip
        shell: bash
        run: |
          set -e
          mkdir -p summary
          MR_NA="$(find artifacts -type f -iname 'morning_report_na.md' -print -quit || true)"
          MR_EU="$(find artifacts -type f -iname 'morning_report_europe.md' -print -quit || true)"
          MR_AP="$(find artifacts -type f -iname 'morning_report_apac.md' -print -quit || true)"
          {
            echo "# Global Summary"
            echo
            if [[ -s "$MR_NA" ]]; then echo "## NA"; echo; cat "$MR_NA"; echo; fi
            if [[ -s "$MR_EU" ]]; then echo; echo "## Europe"; echo; cat "$MR_EU"; echo; fi
            if [[ -s "$MR_AP" ]]; then echo; echo "## APAC"; echo; cat "$MR_AP"; echo; fi
          } > summary/global_summary.md
          zip -r reports-all-regions.zip artifacts summary/global_summary.md

      - name: Upload combined bundle
        uses: actions/upload-artifact@v4
        with:
          name: reports-all-regions
          path: reports-all-regions.zip
          retention-days: 14

  email_bundle:
    needs: aggregate
    runs-on: ubuntu-latest
    environment: Vega
    steps:
      - name: Download combined bundle
        uses: actions/download-artifact@v4
        with:
          name: reports-all-regions
          path: dl

      - name: Normalize and show FROM/TO
        id: norm
        shell: bash
        env:
          FROM_VAR: ${{ vars.SENDGRID_FROM || vars.ALERTS_FROM }}
          TO_VAR:   ${{ vars.SENDGRID_TO   || vars.ALERTS_TO   }}
        run: |
          set -e
          FROM=$(printf '%s' "$FROM_VAR" | tr -d '\r' | sed -e 's/^[[:space:]]*//' -e 's/[[:space:]]*$//')
          TO=$(printf '%s' "$TO_VAR" | tr -d '\r' | sed -e 's/^[[:space:]]*//' -e 's/[[:space:]]*$//')
          echo "from=$FROM" >> "$GITHUB_OUTPUT"
          echo "to=$TO" >> "$GITHUB_OUTPUT"
          echo "Using FROM=$FROM TO=$TO"

      - name: Check attachment size
        id: size
        shell: bash
        run: |
          set -e
          FILE="dl/reports-all-regions.zip"
          if [[ ! -s "$FILE" ]]; then
            echo "::warning::No combined bundle found; nothing to email."
            echo "oversize=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          BYTES=$(stat -c%s "$FILE" 2>/dev/null || stat -f%z "$FILE")
          echo "bytes=$BYTES" >> "$GITHUB_OUTPUT"
          if [ "$BYTES" -gt 25000000 ]; then
            echo "::warning::Attachment is $BYTES bytes (>25MB). Will send email without attachment."
            echo "oversize=true" >> "$GITHUB_OUTPUT"
          else
            echo "oversize=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Email via SendGrid (primary)
        id: sg
        env:
          SG_KEY: ${{ secrets.SENDGRID_API_KEY }}
          FROM:   ${{ steps.norm.outputs.from }}
          TO:     ${{ steps.norm.outputs.to }}
          SUBJECT_INPUT: ${{ github.event.inputs.email_subject }}
          DEFAULT_SUBJECT: ${{ env.DEFAULT_EMAIL_SUBJECT }}
          BODY_DEFAULT: ${{ env.DEFAULT_EMAIL_BODY }}
        shell: bash
        run: |
          set -e
          if [[ -z "${SG_KEY:-}" || -z "${FROM:-}" || -z "${TO:-}" ]]; then
            echo "no_sg=true" >> "$GITHUB_OUTPUT"
            echo "::warning::SendGrid not configured (key or addresses missing); skipping primary."
            exit 0
          fi
          FILE="dl/reports-all-regions.zip"
          SUBJECT="${SUBJECT_INPUT:-$DEFAULT_SUBJECT}"
          printf '%s' "$BODY_DEFAULT" > body.txt

          if [[ "${{ steps.size.outputs.oversize }}" == "true" || ! -s "$FILE" ]]; then
            jq -n \
              --arg from "$FROM" \
              --arg to "$TO" \
              --arg subject "$SUBJECT" \
              --rawfile content body.txt \
              '{
                personalizations: [{ to: [{ email: $to }] }],
                from: { email: $from }, subject: $subject,
                content: [{ type: "text/plain", value: $content }]
              }' > payload.json
          else
            base64 -w 0 "$FILE" > b64.txt
            jq -n \
              --arg from "$FROM" \
              --arg to "$TO" \
              --arg subject "$SUBJECT" \
              --rawfile content body.txt \
              --rawfile b64 b64.txt \
              '{
                personalizations: [{ to: [{ email: $to }] }],
                from: { email: $from }, subject: $subject,
                content: [{ type: "text/plain", value: $content }],
                attachments: [{
                  content: $b64,
                  type: "application/zip",
                  filename: "reports-all-regions.zip"
                }]
              }' > payload.json
          fi

          CODE=$(curl -sS -o response.json -w "%{http_code}" \
            -X POST https://api.sendgrid.com/v3/mail/send \
            -H "Authorization: Bearer ${SG_KEY}" \
            -H "Content-Type: application/json" \
            --data @payload.json)

          echo "http_code=$CODE" >> "$GITHUB_OUTPUT"
          echo "=== SendGrid response (HTTP $CODE) ==="
          cat response.json || true

          if [ "$CODE" != "202" ]; then
            echo "::error::SendGrid returned HTTP $CODE"
            exit 1
          fi

      - name: Fallback via Gmail SMTP (only if SG skipped/failed)
        if: failure() || steps.sg.outputs.no_sg == 'true'
        env:
          MAIL_USER:         ${{ secrets.MAIL_USER }}
          MAIL_APP_PASSWORD: ${{ secrets.MAIL_APP_PASSWORD }}
          MAIL_TO:           ${{ secrets.MAIL_TO }}
        shell: bash
        run: |
          set -e
          if [[ -z "${MAIL_USER:-}" || -z "${MAIL_APP_PASSWORD:-}" || -z "${MAIL_TO:-}" ]]; then
            echo "::warning::No Gmail SMTP secrets; cannot send fallback."
            exit 0
          fi
          python - <<'PY'
import os, smtplib, ssl, base64
from email.message import EmailMessage
FILE = "dl/reports-all-regions.zip"
msg = EmailMessage()
msg['Subject'] = "Reports - All Regions (fallback SMTP)"
msg['From'] = os.environ['MAIL_USER']
msg['To'] = os.environ['MAIL_TO']
msg.set_content("Combined bundle attached if within provider limits.")
if os.path.exists(FILE):
    with open(FILE, 'rb') as f:
        data = f.read()
    msg.add_attachment(data, maintype="application", subtype="zip", filename="reports-all-regions.zip")
with smtplib.SMTP_SSL("smtp.gmail.com", 465, context=ssl.create_default_context()) as s:
    s.login(os.environ['MAIL_USER'], os.environ['MAIL_APP_PASSWORD'])
    s.send_message(msg)
print("[smtp] sent fallback email")
PY

  monthly_release:
    needs: aggregate
    runs-on: ubuntu-latest
    steps:
      - name: Decide whether to create release
        id: gate
        shell: bash
        run: |
          FORCE="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.force_monthly_release == 'true' }}"
          DOM="$(date -u +%d)"
          if [[ "$FORCE" == "true" ]]; then
            echo "run_release=true" >> "$GITHUB_OUTPUT"
          elif [[ "${GITHUB_EVENT_NAME}" == "schedule" && "$DOM" == "01" ]]; then
            echo "run_release=true" >> "$GITHUB_OUTPUT"
          else
            echo "run_release=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Download combined bundle
        if: steps.gate.outputs.run_release == 'true'
        uses: actions/download-artifact@v4
        with:
          name: reports-all-regions
          path: dl

      - name: Download per-region zips
        if: steps.gate.outputs.run_release == 'true'
        uses: actions/download-artifact@v4
        with:
          pattern: report-*
          path: dl
          merge-multiple: true

      - name: Compute release meta
        if: steps.gate.outputs.run_release == 'true'
        id: meta
        shell: bash
        run: |
          YMD="$(date -u +%Y-%m-%d)"; YM="$(date -u +%Y-%m)"
          echo "ymd=$YMD" >> "$GITHUB_OUTPUT"; echo "ym=$YM" >> "$GITHUB_OUTPUT"

      - name: Create GitHub Release (monthly)
        if: steps.gate.outputs.run_release == 'true'
        uses: softprops/action-gh-release@v2
        with:
          tag_name: monthly-${{ steps.meta.outputs.ym }}
          name: Monthly Reports - ${{ steps.meta.outputs.ym }}
          body: |
            Automated monthly export for ${{ steps.meta.outputs.ymd }}.
            Includes: reports-all-regions.zip and per-region bundles (if present).
          files: |
            dl/reports-all-regions.zip
            dl/report_*.zip

  cleanup:
    needs: aggregate
    runs-on: ubuntu-latest
    permissions:
      actions: write
      contents: read
    steps:
      - name: Check if Saturday (UTC) on schedule
        id: daycheck
        shell: bash
        run: |
          if [[ "${GITHUB_EVENT_NAME}" != "schedule" ]]; then
            echo "run_cleanup=false" >> "$GITHUB_OUTPUT"; exit 0; fi
          DOW="$(date -u +%u)"
          [[ "$DOW" == "6" ]] && echo "run_cleanup=true" >> "$GITHUB_OUTPUT" || echo "run_cleanup=false" >> "$GITHUB_OUTPUT"

      - name: Delete artifacts older than 14 days
        if: steps.daycheck.outputs.run_cleanup == 'true'
        uses: actions/github-script@v7
        env:
          RETAIN_DAYS: '14'
        with:
          script: |
            const owner = context.repo.owner, repo = context.repo.repo;
            const days = parseInt(process.env.RETAIN_DAYS || '14', 10);
            const cutoff = Date.now() - days*24*60*60*1000;
            let deleted=0, kept=0;
            for await (const page of github.paginate.iterator(
              github.rest.actions.listArtifactsForRepo, { owner, repo, per_page: 100 })) {
              for (const a of page.data) {
                const created = Date.parse(a.created_at);
                if (!a.expired && created < cutoff) {
                  await github.rest.actions.deleteArtifact({ owner, repo, artifact_id: a.id });
                  deleted++;
                } else { kept++; }
              }
            }
            core.summary.addHeading('Artifact Cleanup')
              .addRaw(`Deleted: ${deleted} • Kept: ${kept} • Cutoff: ${new Date(cutoff).toISOString()}`)
              .write();

      - name: Delete old workflow runs (keep 20, only if >30 days old)
        if: steps.daycheck.outputs.run_cleanup == 'true'
        uses: actions/github-script@v7
        env:
          KEEP_PER_WF: '20'
          RUNS_MAX_AGE_DAYS: '30'
        with:
          script: |
            const owner = context.repo.owner, repo = context.repo.repo;
            const keep = parseInt(process.env.KEEP_PER_WF || '20', 10);
            const maxAgeDays = parseInt(process.env.RUNS_MAX_AGE_DAYS || '30', 10);
            const cutoff = Date.now() - maxAgeDays*24*60*60*1000;
            const runs = await github.paginate(
              github.rest.actions.listWorkflowRunsForRepo, { owner, repo, per_page: 100, status: 'completed' });
            const groups = {};
            for (const r of runs) { const key = `${r.workflow_id}:${r.name || ''}`; (groups[key] ||= []).push(r); }
            let deleted=0, kept=0;
            for (const key of Object.keys(groups)) {
              const list = groups[key].sort((a,b)=> new Date(b.created_at) - new Date(a.created_at));
              for (const [i, run] of list.entries()) {
                const isOld = Date.parse(run.created_at) < cutoff;
                if (i >= keep && isOld) {
                  await github.rest.actions.deleteWorkflowRun({ owner, repo, run_id: run.id });
                  deleted++;
                } else { kept++; }
              }
            }
            core.summary.addHeading('Run Cleanup')
              .addRaw(`Deleted runs: ${deleted} • Kept: ${kept} • Cutoff: ${new Date(cutoff).toISOString()} • Keep per WF: ${keep}`)
              .write();
